# LOGGING LEVELS
LOG_RUNNER_LEVEL=INFO
LOG_DOC_LEVEL=INFO
LOG_KNOWLEDGE_LEVEL=INFO
LOG_MODEL_POOL_LEVEL=INFO
LOG_TOOL_LEVEL=INFO

# LLM MODEL CONFIGURATION
# -------------------------------
# GGUF MODELS
# -------------------------------
LLM_MODEL=bartowski/Qwen2.5-7B-Instruct-GGUF/Qwen2.5-7B-Instruct-Q4_K_M.gguf
# -------------------------------
# LLM_MODEL=Qwen/Qwen2-1.5B-Instruct-GGUF/qwen2-1_5b-instruct-q4_k_m.gguf
# -------------------------------
LLM_BACKEND=llama_cpp
LLM_DEVICE=auto
LLM_DTYPE=auto
# -------------------------------
# Transformer models
# -------------------------------
# GPT-OSS need a lot of resources
# LLM_MODEL=openai/gpt-oss-20b
# LLM_BACKEND=transformers
# LLM_DEVICE=cpu
# LLM_DTYPE=float32
# -------------------------------
# LLM_MODEL=Qwen/Qwen2.5-7B-Instruct
# LLM_BACKEND=transformers
# LLM_DEVICE=auto
# LLM_DTYPE=auto
# LLM_QUANTIZATION=4bit
# -------------------------------
LLM_MAX_NEW_TOKENS=2048
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9
# LLM_QUANTIZATION=4bit
LLM_MODELS_DIR=./models
LLM_GPU_LAYERS=-1
LLM_N_CTX=32768
LLM_N_BATCH=2048

# LLM_STOP_TOKENS=</s>,<|endoftext|>,### 
LLM_MAX_SEARCH_RESULTS=5

# KNOWLEDGE DATABASE CONFIGURATION
KB_TYPE=chromadb
KB_CHROMA_PERSIST_DIRECTORY=./chroma_db
KB_CHROMA_RETRIEVE_COLLECTION=knowledge_retrieval
KB_CHROMA_CONTEXT_COLLECTION=knowledge_context
KB_CHROMA_DOCUMENT_COLLECTION=knowledge_documents
KB_CHROMA_BATCH_SIZE=100
KB_CHROMA_EMBEDDING_MODEL=all-MiniLM-L6-v2
KB_CHROMA_EMBEDDING_MODEL_DIR=./models
KB_CHROMA_RETRIEVAL_CHUNK_SIZE=128
KB_CHROMA_RETRIEVAL_CHUNK_OVERLAP=20
KB_CHROMA_CONTEXT_CHUNK_SIZE=1024
KB_CHROMA_CONTEXT_CHUNK_OVERLAP=100
