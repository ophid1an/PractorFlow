[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "PractorFlow"
version = "0.0.1"
description = "PractorFlow - Private AI Service for local LLM inference with RAG support"
readme = "../../README.md"
license = "MIT"
requires-python = ">=3.10"
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
keywords = ["llm", "ai", "rag", "inference", "local", "private"]

dependencies = [
    "llama-cpp-python",
    "torch",
    "transformers",
    "accelerate",
    "protobuf",
    "docling",
    "chardet",
    "mistral-common",
    "sentence-transformers",
    "chromadb",
    "bitsandbytes",
    "ddgs",
    "serpapi",
    "pydantic-ai",
    "python-dotenv",
    "numpy",
    "huggingface-hub",
]

[project.optional-dependencies]
llama-cpp = [
    "llama-cpp-python",
]
dev = [
    "pytest",
    "pytest-asyncio",
    "black",
    "isort",
    "mypy",
]

[project.urls]
Homepage = "https://github.com/vbouzoukos/PractorFlow"
Documentation = "https://github.com/vbouzoukos/PractorFlow#readme"
Repository = "https://github.com/vbouzoukos/PractorFlow"
Issues = "https://github.com/vbouzoukos/PractorFlow/issues"

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
practorflow = ["py.typed"]

[tool.black]
line-length = 88
target-version = ["py310", "py311", "py312"]

[tool.isort]
profile = "black"
line_length = 88

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true